{"cells": [{"cell_type": "markdown", "metadata": {"_uuid": "d6576d078c298c71f783ae570d9e1941be2924ed", "_cell_guid": "690f98f7-648f-4146-8aa4-6a47fbb72883"}, "source": ["# An\u00e1lise de Sentimentos em l\u00edngua portuguesa do Brasil\n", "\n", "Exemplo did\u00e1tico de an\u00e1lise de sentimentos a partir de uma base de dados de tweets classificados classificados como positivo, negativo e neutro. Baseado no trabalho do Minerando Dados (https://github.com/minerandodados)."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "2840dd041b764e287b641cc8308c68c520796d9b", "_cell_guid": "6f03ca1a-3c0e-4e33-9ba6-91a9d640185f"}, "source": ["# This Python 3 environment comes with many helpful analytics libraries installed\n", "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n", "\n", "import nltk\n", "import re\n", "import pandas as pd\n", "from sklearn.feature_extraction.text import CountVectorizer\n", "from sklearn.naive_bayes import MultinomialNB\n", "from sklearn import metrics\n", "from sklearn.model_selection import cross_val_predict\n", "\n", "# Input data files are available in the \"../input/\" directory.\n", "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n", "\n", "from subprocess import check_output\n", "print(check_output([\"ls\", \"-l\", \"../input\"]).decode(\"utf8\"))\n", "\n", "# Any results you write to the current directory are saved as output."]}, {"cell_type": "markdown", "metadata": {"_uuid": "af447214f6b3b7791f19e4a17488198659a5e6ab", "_cell_guid": "a9cdc1e8-0e19-4f98-a377-1a8efa50331c"}, "source": ["## 1. O Dataset de Tweets\n", "Vamos come\u00e7ar inspecionando nosso dataset."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "7b761277e1b96610ba67f19b27b52d6658acd2bb", "_cell_guid": "f1f48f72-4db1-4734-8723-9ef52aedc7b0"}, "source": ["# Primeiro, vamos contar a quantidade total de registros\n", "dataset = pd.read_csv('../input/Tweets_Mg.csv',encoding='utf-8')\n", "dataset.count()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "cf33f8ba0a1faf5aced6cb0769d39407ac08ee76", "_cell_guid": "f2cfc532-207d-4d45-9110-bfefafa97b2a"}, "source": ["# Agora, apenas os classificados como neutro\n", "dataset[dataset.Classificacao == 'Neutro'].count()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "ab681c0af0991060c8b176adf95d0438097715f9", "_cell_guid": "e3d854fb-edab-4a8c-a22a-c41782f1db5a"}, "source": ["# Os classificados como positivo\n", "dataset[dataset.Classificacao == 'Positivo'].count()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "d8c95fe8a2ff1114161f3af20a87dfabb80d3048", "_cell_guid": "1241d7f5-12c6-4f4f-9c0f-4355f1195d8f"}, "source": ["# E finalmente, os classificados como negativo\n", "dataset[dataset.Classificacao == 'Negativo'].count()"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "7c04a528851a3fa57b89a1ad33826456a423e7f0", "_cell_guid": "978a0209-71be-443d-8748-88f7c1cef6c5"}, "source": ["# OK, vamos dar uma olhada r\u00e1pida no conte\u00fado do dataset para finalizar esse passo\n", "dataset.head()"]}, {"cell_type": "markdown", "metadata": {"_uuid": "73de912a022494b152d915d3ea31ca18c14d718b", "_cell_guid": "f39fe03f-981f-4629-b79a-50098dd59924"}, "source": ["## 2. Construindo o Modelo"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "0b90c933012a38041e975f66a60f377915b92112", "_cell_guid": "eca2a77a-f355-41c5-ad4a-dfbe32af62f4"}, "source": ["# Pr\u00f3ximo passo, vamos separar os tweets e suas classes\n", "tweets = dataset[\"Text\"].values\n", "tweets"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "866709548dc8dabc53c1c758f0bfdf410182a19d", "_cell_guid": "69e04867-3f0f-47d2-88f5-df2127042d1b"}, "source": ["classes = dataset[\"Classificacao\"].values\n", "classes"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a376262987475125694411ecb7e129f07e84e8f3", "_cell_guid": "007fbaef-b5d0-4fd7-92cc-2583ba668179"}, "source": ["# Agora, vamos treinar o modelo usando a abordagem Bag of Words e o algoritmo Naive Bayes Multinomial\n", "#    - Bag of Words, na pr\u00e1tica, cria um vetor com cada uma das palavras do texto completo da base,\n", "#      depois, calcula a frequ\u00eancia em que essas palavras ocorrem em uma data senten\u00e7a, para ent\u00e3o\n", "#      classificar/treinar o modelo\n", "#    - Exemplo HIPOT\u00c9TICO de tr\u00eas senten\u00e7as vetorizadas \"por palavra\" e classificadas baseada na\n", "#      frequ\u00eancia de suas palavras:\n", "#         {0,3,2,0,0,1,0,0,0,1, Positivo}\n", "#         {0,0,1,0,0,1,0,1,0,0, Negativo}\n", "#         {0,1,1,0,0,1,0,0,0,0, Neutro}\n", "#    - Olhando para esses vetores, meu palpite \u00e9 que as palavras nas posi\u00e7\u00f5es 2 e 3 s\u00e3o as com maior\n", "#      peso na determina\u00e7\u00e3o de a que classe pertence cada uma das tr\u00eas senten\u00e7as avaliadas\n", "#    - A fun\u00e7\u00e3o fit_transform faz exatamente esse processo: ajusta o modelo, aprende o vocabul\u00e1rio,\n", "#      e transforma os dados de treinamento em feature vectors, a.k.a. vetor com frequ\u00eacia das palavras\n", "\n", "vectorizer = CountVectorizer(analyzer = \"word\")\n", "freq_tweets = vectorizer.fit_transform(tweets)\n", "\n", "modelo = MultinomialNB()\n", "modelo.fit(freq_tweets, classes)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "f55fb6c880a34170862eaf35be8f594d9e280460", "_cell_guid": "466d7f29-032e-4dec-9602-94dd38109d3a"}, "source": ["## 3. Testando o modelo"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "68bc8d6fc38abf056dca0a39b687d1c381f8fd25", "_cell_guid": "455dcddd-6b44-4a28-97c3-fa08f0fee171"}, "source": ["# Vamos usar algumas frases de teste para fazer a classifica\u00e7\u00e3o com o modelo treinado\n", "testes = [\"Esse governo est\u00e1 no in\u00edcio, vamos ver o que vai dar\",\n", "          \"Estou muito feliz com o governo de S\u00e3o Paulo esse ano\",\n", "          \"O estado de Minas Gerais decretou calamidade financeira!!!\",\n", "          \"A seguran\u00e7a desse pa\u00eds est\u00e1 deixando a desejar\",\n", "          \"O governador de Minas \u00e9 do PT\",\n", "          \"O prefeito de S\u00e3o Paulo est\u00e1 fazendo um \u00f3timo trabalho\"]\n", "\n", "freq_testes = vectorizer.transform(testes)\n", "modelo.predict(freq_testes)"]}, {"cell_type": "markdown", "metadata": {"_uuid": "170c7c69f73a7433a0554d44a98a62308e08fc9f", "_cell_guid": "179b67d3-0050-4188-a605-b70907e14336"}, "source": ["## 4. Avaliando o modelo"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "7cff21dfc9bb07fbce32ab78ed3073b13bdc021b", "_cell_guid": "6afb7e0c-ce1c-497b-8f2f-02b75587954e"}, "source": ["# Valida\u00e7\u00e3o cruzada do modelo. Neste caso, o modelo \u00e9 dividido em 10 partes, treinado em 9 e testado em 1\n", "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n", "resultados"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e8eb430cb4d6449c8f173c27fbac4fc4ec711bb3", "_cell_guid": "b6b63681-0961-4da4-bd40-3c73cf0884cd"}, "source": ["# Qu\u00e3o acurada \u00e9 a m\u00e9dia do modelo?\n", "metrics.accuracy_score(classes, resultados)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "1fb21da856cc6c4ee65f7daa95137dcdfbb51c0d", "_cell_guid": "a2b917b7-da10-4403-b0a7-f6f88897e29d"}, "source": ["# Medidas de valida\u00e7\u00e3o do modelo\n", "sentimentos = [\"Positivo\", \"Negativo\", \"Neutro\"]\n", "print(metrics.classification_report(classes, resultados, sentimentos))\n", "\n", "# Lembrando que:\n", "#    : precision = true positive / (true positive + false positive)\n", "#    : recall    = true positive / (true positive + false negative)\n", "#    : f1-score  = 2 * ((precision * recall) / (precision + recall))"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "aaa2cc41ea529a09c8a3c8fe504457b02769ea59", "_cell_guid": "ffda64a4-e0cf-443c-bb53-a1a6f2024ae1"}, "source": ["# Vamos fazer uma matriz de confus\u00e3o -- What?!?!\n", "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames=[\"Predito\"], margins=True))\n", "\n", "# Lembrando que:\n", "#    - Predito = O que o programa classificou como Negativo, Neutro, Positivo e All\n", "#    - Real    = O que \u00e9 de fato Negativo, Neutro, Positivo e All\n", "#\n", "# Ou seja, somente 9 tweets eram de fato negativos e o programa classificou como positivos. J\u00e1 os\n", "# positivos que o programa classificou como negativos foram 45, muito mais"]}, {"cell_type": "markdown", "metadata": {"_uuid": "0c355e4fb76bd97a114473c71a49872dcd5b5c75", "_cell_guid": "0354f18c-b26d-42e9-b5b8-945b931cc2a0"}, "source": ["## 5. Melhorando o modelo"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c4db254fe1fa38a0d05067708d37e65f007eb118", "_cell_guid": "8dfc7e26-78fe-4233-89db-3795d4c360bd"}, "source": ["# Com o modelo de Bigrams, em lugar de vetorizar o texto \"por palavra\", vamos vetoriza-lo por cada\n", "# \"duas palavras\", tipo: Eu gosto de S\u00e3o Paulo => { eu gosto, gosto de, de s\u00e3o, s\u00e3o paulo }\n", "vectorizer = CountVectorizer(ngram_range = (1, 2))\n", "freq_tweets = vectorizer.fit_transform(tweets)\n", "\n", "modelo = MultinomialNB()\n", "modelo.fit(freq_tweets, classes)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "a6b6fe306e4a46b24150f858d88fa9b49bb58575", "_cell_guid": "e918cdc1-a49c-4868-9218-047af413b4c5"}, "source": ["# Nova predi\u00e7\u00e3o bigramada\n", "resultados = cross_val_predict(modelo, freq_tweets, classes, cv = 10)\n", "resultados"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "89647d6fedfb0d600c4d32bda31a95a4b7e6c83a", "_cell_guid": "eeac7ad5-01ee-495b-b014-a3cbeda59abc"}, "source": ["# Qual foi a acuracidade desse novo modelo?\n", "metrics.accuracy_score(classes, resultados)"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "3ae3973a12114a23096b0d35dfa298c36340a901", "_cell_guid": "ac06ba72-6bd4-41c7-8175-e1604f179ee5"}, "source": ["# As novas medidas de valida\u00e7\u00e3o do modelo, um pouquinho melhor que o anterior\n", "print(metrics.classification_report(classes, resultados, sentimentos))"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "fcddb076247e620c096b02b7d5562a63d14c79ec", "_cell_guid": "6ba7bd8e-30ea-42dc-929e-39bfc54ed323"}, "source": ["# E a nova matriz de confus\u00e3o\n", "print(pd.crosstab(classes, resultados, rownames = [\"Real\"], colnames = [\"Predito\"], margins = True))\n", "\n", "# Mudan\u00e7as em rela\u00e7\u00e3o ao modelo anterior:\n", "#\n", "#    - Negativo-negativo = 2275 vs 2265 (piorou)\n", "#    - Negativo-neutro   = 162  vs 179  (piorou)\n", "#    - Negativo-positivo = 9    vs 2    (melhorou)\n", "#\n", "#    - Positivo-positivo = 2899 vs 2900 (melhorou)\n", "#    - Positivo-neutro   = 356  vs 357  (piorou)\n", "#    - Positivo-negativo = 45   vs 43   (melhorou)\n", "#\n", "#    - Neutro-neutro     = 2067 vs 2177 (melhorou)\n", "#    - Neutro-negativo   = 240  vs 181  (melhorou)\n", "#    - Neutro-positivo   = 146  vs 95   (melhorou)\n", "#\n", "# Tabela anterior para refer\u00eancia:\n", "#\n", "#    Predito   Negativo  Neutro  Positivo   All\n", "#    Real                                      \n", "#    Negativo      2275     162         9  2446\n", "#    Neutro         240    2067       146  2453\n", "#    Positivo        45     356      2899  3300\n", "#    All           2560    2585      3054  8199"]}, {"cell_type": "markdown", "metadata": {"_uuid": "23667044df7fc4bc823e300200974a489d4fe80d", "_cell_guid": "e110fa95-d680-4be2-9eda-1270ef26b46c"}, "source": ["# B\u00f4nus"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "8da2509f419ffdfcfc0441af686d91a6b9eb90fa", "_cell_guid": "37a22b03-e440-4ad4-8281-de61479ab563"}, "source": ["# Vamos reinicializar nosso bag of words com um par\u00e2metro de m\u00e1ximo de features\n", "vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None,\n", "                             stop_words = None, max_features = 5000)\n", "\n", "# Treinar o modelo, aprender o vocabul\u00e1rio e transformar nossos dados de treinamento em feature vectors\n", "train_data_features = vectorizer.fit_transform(tweets)\n", "train_data_features"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "5b5372b7009069ca8dff959ae95137033cb3b25e", "_cell_guid": "85de9639-ac4a-4934-a572-949001f190bd"}, "source": ["# Hora de iniciar um classificador Random Forest\n", "from sklearn.ensemble import RandomForestClassifier\n", "forest = RandomForestClassifier(n_estimators = 100)\n", "forest"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "99f6f55b07fbac58fb42206feb8ef3526a21981d", "_cell_guid": "7d9c25be-4942-4bf0-8cb0-f018a38edb09"}, "source": ["# Separar os sentimentos do dataset de tweets\n", "class_sentimentos = dataset[\"Classificacao\"].values\n", "class_sentimentos"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e65add0e8b5bbd16f5e819f4794ff728539551a2", "_cell_guid": "ff88013f-fbd2-4ec4-8ec6-cc7e45b4957a"}, "source": ["# Ajusta a forest ao dataset de treinamento usando a bag of words como feature e os sentimentos\n", "# como a resposta vari\u00e1vel\n", "forest = forest.fit(train_data_features, class_sentimentos)\n", "forest"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "20aa2583db7ecf91e02bc945c6cdadde568abd63", "_cell_guid": "a05bc498-14b4-4f7f-b7a7-d308d0067ccd"}, "source": ["# Criar a bag of words de teste\n", "test_data_features = vectorizer.transform(testes)\n", "test_data_features"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "de46ae32c3eeb3fd1fc1388d7573146516541100", "_cell_guid": "9e4a1300-7b5a-4f3d-ab27-d3c8f5f265ab"}, "source": ["# Fazer um predi\u00e7\u00e3o\n", "resultados = forest.predict(test_data_features)\n", "resultados\n", "\n", "# Resultado que tivemos com o primeiro modelo:\n", "# array(['Neutro', 'Neutro', 'Negativo', 'Negativo', 'Neutro', 'Positivo'], dtype='<U8')\n", "#\n", "# Meh."]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "e824df8f567108ab50f2f39aba588612bfed3dd3", "_cell_guid": "05e502f3-c4ad-44e1-9480-eb7ce21202f0"}, "source": ["# Que tal gerar uma tabelinha Pandas?\n", "testes_id = [1, 2, 3, 4, 5, 6]\n", "\n", "data_frame = pd.DataFrame(data = { \"id\": testes_id, \"texto\": testes, \"sentimento\": resultados })\n", "data_frame"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "507f81f018ac63e1c7f46ac5140d178b0f3d8297", "_cell_guid": "b2f278ac-2ff5-49dc-9461-b4b62d45c30a"}, "source": ["# E finalmente, vamos salvar nossa predi\u00e7\u00e3o em um .csv\n", "data_frame.to_csv(\"tweets_classificados_por_forest.csv\", index = False, quoting = 3, escapechar = \"\\\\\")\n", "print(check_output([\"ls\", \"-l\", \".\"]).decode(\"utf8\"))"]}, {"outputs": [], "execution_count": null, "cell_type": "code", "metadata": {"_uuid": "c4675aedf2a2e46b5642fbe8fd9f78c74a26cc74", "_cell_guid": "5d1e2db8-a0b7-49de-ba13-f501cfc9d86d"}, "source": ["# OK, ok, vamos dar s\u00f3 mais uma espiada para ver se deu tudo certo\n", "print(check_output([\"cat\", \"tweets_classificados_por_forest.csv\"]).decode(\"utf8\"))"]}], "nbformat_minor": 1, "metadata": {"language_info": {"codemirror_mode": {"version": 3, "name": "ipython"}, "mimetype": "text/x-python", "name": "python", "file_extension": ".py", "nbconvert_exporter": "python", "version": "3.6.4", "pygments_lexer": "ipython3"}, "kernelspec": {"display_name": "Python 3", "name": "python3", "language": "python"}}, "nbformat": 4}